fullnameOverride: promstack
crds:
    enabled: true
    upgradeJob:
        enabled: true
        forceConflicts: true
defaultRules:
    create: false
additionalPrometheusRulesMap:
    self:
        groups:
            - name: PromStack
              rules:
                - alert: PrometheusJobMissing
                  expr: absent(up{job="promstack-prometheus"})
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus job is missing
                    description: A Prometheus job on endpoint {{ $labels.endpoint }} has disappeared
                - alert: PrometheusTargetMissing
                  expr: up == 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus target is missing
                    description: Prometheus job={{ $labels.job }}, hostname={{ $labels.hostname }} has disappeared. An exporter might be crashed.
                - alert: PrometheusConfigurationReloadFailure
                  expr: prometheus_config_last_reload_successful != 1
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus configuration reload failure
                    description: Prometheus configuration reload error
                - alert: PrometheusTooManyRestarts
                  expr: changes(process_start_time_seconds{job=~"^promstack.*"}[10m]) > 2
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus too many restarts on {{ $labels.job}}
                    description: Prometheus has restarted {{ $value }} times (>2) in the last 10 minutes. It might be crashlooping.
                - alert: PrometheusAlertmanagerJobMissing
                  expr: absent(up{job="promstack-alertmanager"})
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus AlertManager job missing (instance {{ $labels.instance }})
                    description: A Prometheus AlertManager job on endpoint {{ $labels.endpoint }} has disappeared
                - alert: PrometheusAlertmanagerConfigurationReloadFailure
                  expr: alertmanager_config_last_reload_successful != 1
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus AlertManager configuration reload failure
                    description: AlertManager configuration reload error
                - alert: PrometheusAlertmanagerE2eDeadManSwitch
                  expr: vector(1)
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus AlertManager E2E dead man switch (instance {{ $labels.instance }})
                    description: |-
                        Prometheus DeadManSwitch is an always-firing alert. It's used as an end-to-end test of Prometheus through the Alertmanager.
                          VALUE = {{ $value }}
                          LABELS = {{ $labels }}
                - alert: PrometheusNotConnectedToAlertmanager
                  expr: prometheus_notifications_alertmanagers_discovered < 1
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus not connected to alertmanager"
                    description: Prometheus cannot connect the alertmanager
                - alert: PrometheusTargetEmpty
                  expr: prometheus_sd_discovered_targets == 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus target empty
                    description: Prometheus has no target in service discovery on {{ $labels.config }}
                - alert: PrometheusTargetScrapeDuplicate
                  expr: increase(prometheus_target_scrapes_sample_duplicate_timestamp_total[5m]) > 0
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus target scrape duplicate
                    description: Prometheus has many samples rejected due to duplicate timestamps but different values
                - alert: PrometheusTsdbCheckpointCreationFailures
                  expr: increase(prometheus_tsdb_checkpoint_creations_failed_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB checkpoint creation failures
                    description: Prometheus encountered {{ $value }} checkpoint creation failures
                - alert: PrometheusTsdbCheckpointDeletionFailures
                  expr: increase(prometheus_tsdb_checkpoint_deletions_failed_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB checkpoint deletion failures
                    description: Prometheus encountered {{ $value }} checkpoint deletion failures
                - alert: PrometheusTsdbCompactionsFailed
                  expr: increase(prometheus_tsdb_compactions_failed_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB compactions failed
                    description: Prometheus encountered {{ $value }} TSDB compactions failures
                - alert: PrometheusTsdbHeadTruncationsFailed
                  expr: increase(prometheus_tsdb_head_truncations_failed_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB head truncations failed
                    description: Prometheus encountered {{ $value }} TSDB head truncation failures
                - alert: PrometheusTsdbReloadFailures
                  expr: increase(prometheus_tsdb_reloads_failures_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB reload failures
                    description: Prometheus encountered {{ $value }} TSDB reload failures
                - alert: PrometheusTsdbWalCorruptions
                  expr: increase(prometheus_tsdb_wal_corruptions_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB WAL corruptions
                    description: Prometheus encountered {{ $value }} TSDB WAL corruptions
                - alert: PrometheusTsdbWalTruncationsFailed
                  expr: increase(prometheus_tsdb_wal_truncations_failed_total[1m]) > 0
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Prometheus TSDB WAL truncations failed
                    description: Prometheus encountered {{ $value }} TSDB WAL truncation failures
                - alert: PrometheusTimeseriesCardinality
                  expr: label_replace(count by(__name__) ({__name__=~".+"}), "name", "$1", "__name__", "(.+)") > 10000
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Prometheus timeseries cardinality explosion
                    description: 'The "{{ $labels.name }}" timeseries cardinality is getting very high: {{ $value }} (>10000)'
    node-exporter:
        groups:
            - name: NodeExporter
              rules:
                - alert: HostOutOfMemory
                  expr: sum by (hostname) (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes ) < .10
                  for: 2m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` is out of memory
                    description: Memory is at {{ $value | humanizePercentage }} (< 10% left)
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostMemoryUnderMemoryPressure
                  expr: sum by (hostname) (rate(node_vmstat_pgmajfault[5m]) > 500)
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` under memory pressure
                    description: Heavy memory pressure, rate of loading memory pages from disk is at {{ $value | humanize }} (pgmajfault > 500/s)
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostUnusualNetworkThroughputIn
                  expr: sum by (hostname, device) (rate(node_network_receive_bytes_total[5m]) / node_network_speed_bytes) > .80
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` unusual network Ingress throughput
                    description: Ingress bandwidth is high at {{ $value | humanizePercentage }} (>80%) on interface {{ $labels.device }}
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostUnusualNetworkThroughputOut
                  expr: (sum by (hostname, device) (rate(node_network_transmit_bytes_total[5m]) / node_network_speed_bytes)) > .80
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` unusual network Egress throughput
                    description: Egress bandwidth is high at {{ $value | humanizePercentage }} (>80%) on interface {{ $labels.device }}
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostUnusualDiskReadRate
                  expr: sum by (hostname, device) (rate(node_disk_io_time_seconds_total[5m])) > .80
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    description: Host `{{ $labels.hostname }}` disk is too busy
                    summary: Disk read rate is at {{ $value | humanizePercentage }} (IO wait > 80%) on device {{ $labels.device }}
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                    # Please add ignored mountpoints in node_exporter parameters like
                    # "--collector.filesystem.ignored-mount-points=^/(sys|proc|dev|run)($|/)".
                    # Same rule using "node_filesystem_free_bytes" will fire when disk fills for non-root users.
                - alert: HostOutOfDiskSpace
                  expr: sum by (hostname, device)(node_filesystem_avail_bytes{fstype!~"^(fuse.*|tmpfs|cifs|nfs)"} / node_filesystem_size_bytes < 0.15 and on (hostname, device, mountpoint) node_filesystem_readonly)
                  for: 2m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` out of disk space
                    description: Disk is almost full at {{ $value | humanizePercentage }} (< 15% left) on device {{ $labels.device }}
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostFilesystemDeviceError
                  expr: sum by(hostname, device, mountpoint) (node_filesystem_device_error{fstype!~"^(fuse.*|tmpfs|cifs|nfs)", device!="none"}) > 0
                  for: 2m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` has filesystem device error
                    description: Error stat-ing device {{ $labels.device }}, {{ $labels.mountpoint }} filesystem
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostHighCpuLoad
                  expr: sum by (hostname) (1 - (avg without (cpu) (rate(node_cpu_seconds_total{mode="idle"}[5m])))) > .80
                  for: 10m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` high CPU load
                    description: CPU load is {{ $value | humanizePercentage }} (>80%)
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostCpuStealNoisyNeighbor
                  expr: avg by (hostname) (rate(node_cpu_seconds_total{mode="steal"}[5m])) > .1
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` CPU steal noisy neighbor
                    description: CPU steal is at {{ $value | humanizePercentage }} (>10%). A noisy neighbor is killing VM performances or a spot instance may be out of credit
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostCpuHighIowait
                  expr: avg by (hostname) (rate(node_cpu_seconds_total{mode="iowait"}[5m])) > .10
                  for: 0m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` CPU high iowait
                    description: CPU iowait is at {{ $value | humanizePercentage }} (>10%). Your CPU is idling waiting for storage to respond.
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostContextSwitchingHigh
                  expr: (rate(node_context_switches_total[15m])/count without(mode,cpu) (node_cpu_seconds_total{mode="idle"})) / (rate(node_context_switches_total[1d])/count without(mode,cpu) (node_cpu_seconds_total{mode="idle"})) > 2
                  for: 2m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host {{ $labels.hostname }} context switching high
                    description: Context switching is high (twice the daily average during the last 15m)
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostSwapIsFillingUp
                  expr: sum by (hostname) (1 - (node_memory_SwapFree_bytes / node_memory_SwapTotal_bytes)) > .80
                  for: 2m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` swap is filling up
                    description: Swap is filling up at {{ $value | humanizePercentage }} (>80%)
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostPhysicalComponentTooHot
                  expr: sum by (hostname, chip) (node_hwmon_temp_celsius > node_hwmon_temp_max_celsius)
                  for: 5m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` physical component too hot
                    description: Physical hardware chip {{ $labels.chip }} too hot
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostNodeOvertemperatureAlarm
                  expr: sum by (hostname, chip) ((node_hwmon_temp_crit_alarm_celsius > 0) or (node_hwmon_temp_alarm > 0))
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` node overtemperature alarm
                    description: Physical node temperature alarm triggered for chip {{ $labels.chip }}
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostOomKillDetected
                  expr: sum by (hostname) (increase(node_vmstat_oom_kill[1m]) > 0)
                  for: 0m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` OOM kill detected
                    description: OOM kill detected
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostNetworkReceiveErrors
                  expr: sum by (hostname, device) (rate(node_network_receive_errs_total[2m]) / rate(node_network_receive_packets_total[2m])) > 0.01
                  for: 2m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` Network Receive Errors
                    description: Interface {{ $labels.device }} has encountered {{ $value | humanizePercentage }} (>1%) receive errors in the last 2 minutes
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostNetworkTransmitErrors
                  expr: sum by (hostname, device) (rate(node_network_transmit_errs_total[2m]) / rate(node_network_transmit_packets_total[2m])) > 0.01
                  for: 2m
                  labels:
                    severity: warning
                  annotations:
                    summary: Host `{{ $labels.hostname }}` Network Transmit Errors
                    description: Interface {{ $labels.device }} has encountered {{ $value | humanizePercentage }} (>1%) transmit errors in the last 2 minutes
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostClockSkew
                  expr: ((node_timex_offset_seconds > 0.05 and deriv(node_timex_offset_seconds[5m]) >= 0) or (node_timex_offset_seconds < -0.05 and deriv(node_timex_offset_seconds[5m]) <= 0))
                  for: 10m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` clock skew
                    description: Clock skew detected. Clock is out of sync. Ensure NTP is configured correctly on this host.
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
                - alert: HostClockNotSynchronising
                  expr: (min_over_time(node_timex_sync_status[1m]) == 0 and node_timex_maxerror_seconds >= 16)
                  for: 2m
                  labels:
                    severity: critical
                  annotations:
                    summary: Host `{{ $labels.hostname }}` clock not synchronising
                    description: Clock not synchronising. Ensure NTP is configured on this host.
                    dashboard: ENC[AES256_GCM,data:WLQ0qwyd0ZaZ4gPai3DpQQ5kXDzKXLq+bCh+YLa6dDFN2U51kifO+8/MQyWYd1zs8qv9ozLiYcnhV9C4fa1G3yfgjDbWmiQGC/8EZOSyvTqEZUAVGbtSZ0kY9sAWVgUOJg==,iv:R61uj/w07ccB1vmcO+RxY/o4LLkJDkiIQSCTjoHagtM=,tag:n5t1iA8Ip9CGcaQKakNlQg==,type:str]
alertmanager:
    enabled: true
    config:
        global:
            resolve_timeout: 2m
        route:
            group_by:
                - alertname
                - hostname
            receiver: discord
            group_wait: 30s
            group_interval: 30m
            repeat_interval: 30m
            routes:
                - matchers:
                    - severity =~ "major|critical"
                  receiver: discord-critical
        inhibit_rules:
            - source_matchers:
                - severity = critical
              target_matchers:
                - severity =~ warning|info
              equal:
                - namespace
                - alertname
            - source_matchers:
                - severity = warning
              target_matchers:
                - severity = info
              equal:
                - namespace
                - alertname
            - source_matchers:
                - alertname = InfoInhibitor
              target_matchers:
                - severity = info
              equal:
                - namespace
            - target_matchers:
                - alertname = InfoInhibitor
        receivers:
            - name: discord
              discord_configs:
                - webhook_url: ENC[AES256_GCM,data:kzZYCJVMQqmTg/hvHUjJs1KEXwRqm1gsTblglga7DtvHnP1yVqU1d6SmTV80Bjx661e1yFE26G4BKKDUN72eqArRUuMqYGipwKAnp+BZuFyKg18giYu5vozNVmxgye/WwYUWaMIkyxHTfnLrkhbZyvGqHounCcxUrA==,iv:EVtCeYGmq9h+I/Kq4lCIxDkdY+JEx5ANgu195WMwKMM=,tag:IimEu28SZbjjSFxQVzyDqg==,type:str]
                  send_resolved: true
                  username: Alertmanager
                  avatar_url: https://cdn.jsdelivr.net/gh/homarr-labs/dashboard-icons/png/alertmanager.png
                  title: "{{ if eq .Status \"firing\" }}\U0001F6A8({{ .Alerts.Firing | len }}){{ else }}✅{{ end }} {{ .GroupLabels.alertname }}{{ if .GroupLabels.hostname }} ({{ .GroupLabels.hostname }}){{ end }}"
                  message: "{{ range .Alerts }}\n### {{ .Annotations.summary }}\n**Description:** {{ .Annotations.description }}\n**Severity:** {{ if eq .Labels.severity \"critical\" }}\U0001F6A8{{ else if eq .Labels.severity \"warning\" }}⚠️{{ else }}ℹ️{{ end }} {{ .Labels.severity }}\n**Hostname:** `{{ .Labels.hostname }}`\n**Fired At:** {{ .StartsAt.Format \"2006-01-02 15:04:05 UTC\" }}\n— — — — — — — — — —\n{{- end }}\n[:mag: Query]({{ (index .Alerts 0).GeneratorURL }}) [:bar_chart: Dashboard]({{ (index .Alerts 0).Annotations.dashboard }}) [:no_bell: Silence]({{ template \"__alertmanagerURL\" . }})"
            - name: discord-critical
              discord_configs:
                - webhook_url: ENC[AES256_GCM,data:42z6g0JjowvYhqqLO5z185Ll70bFlp/7VQtJ651xl+ag230Ma0YMMySMxDcM0GfChDSQB+N1fxR93cwFT6k+9Ao7yDwQPfsllp0iBkQEUk+5tjz87V9n1FKEjCSFEIoimlfvpG6ZDeGd+UhaNTSZcr3vq2saB1jtDQ==,iv:zgeiv6LwEpG9N9I5RCuNOUIGnyQrjJNLa3j8UodvZKs=,tag:lu6jhsBG+PArp82FMaMiiQ==,type:str]
                  send_resolved: true
                  username: Alertmanager
                  avatar_url: https://cdn.jsdelivr.net/gh/homarr-labs/dashboard-icons/png/alertmanager.png
                  title: "{{ if eq .Status \"firing\" }}\U0001F6A8({{ .Alerts.Firing | len }}){{ else }}✅{{ end }} {{ .GroupLabels.alertname }}{{ if .GroupLabels.hostname }} ({{ .GroupLabels.hostname }}){{ end }}"
                  message: "{{ range .Alerts }}\n### {{ .Annotations.summary }}\n**Description:** {{ .Annotations.description }}\n**Severity:** {{ if eq .Labels.severity \"critical\" }}\U0001F6A8{{ else if eq .Labels.severity \"warning\" }}⚠️{{ else }}ℹ️{{ end }} {{ .Labels.severity }}\n**Hostname:** `{{ .Labels.hostname }}`\n**Fired At:** {{ .StartsAt.Format \"2006-01-02 15:04:05 UTC\" }}\n— — — — — — — — — —\n{{- end }}\n[:mag: Query]({{ (index .Alerts 0).GeneratorURL }}) [:bar_chart: Dashboard]({{ (index .Alerts 0).Annotations.dashboard }}) [:no_bell: Silence]({{ template \"__alertmanagerURL\" . }})"
    ingress:
        enabled: true
        ingressClassName: nginx
        annotations:
            nginx.ingress.kubernetes.io/auth-method: GET
            nginx.ingress.kubernetes.io/auth-url: http://authelia.ingress.svc.cluster.local/api/verify
            nginx.ingress.kubernetes.io/auth-signin: ENC[AES256_GCM,data:jzPU1mDg9AyKtN1KRzZtNsJDXPUhT9S1ZZaVCQKMSPt9VDAPdCnuvPAL1/5C,iv:T1YIy48IwcgcvoJqh+A1a1G+2Uby5lRdaO26KQT210o=,tag:oaEquHL/TF6ptpUzYDiiqA==,type:str]
            nginx.ingress.kubernetes.io/auth-response-headers: Remote-User,Remote-Name,Remote-Groups,Remote-Email
            nginx.ingress.kubernetes.io/auth-snippet: proxy_set_header X-Forwarded-Method $request_method;
        hosts:
            - ENC[AES256_GCM,data:EUuNAdDYUVQ/w3r6kr66STzdYSm95pQFGfFzrN9JCYA=,iv:PDa67+B5Yap6BlFj6SNJZ8mph7+DUIqQ48+4TE676eI=,tag:TZDdgrf+rS+20xTnz2iGZQ==,type:str]
        tls:
            - secretName: local-wildcard-cert
    ## Configuration for creating a ServiceMonitor for AlertManager
    #
    serviceMonitor:
        selfMonitor: true
    alertmanagerSpec:
        logFormat: logfmt
        logLevel: info
        replicas: 1
        retention: 120h
        ## Storage is the definition of how storage will be used by the Alertmanager instances.
        ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/platform/storage.md
        ##
        storage: {}
        # volumeClaimTemplate:
        #   spec:
        #     storageClassName: gluster
        #     accessModes: ["ReadWriteOnce"]
        #     resources:
        #       requests:
        #         storage: 50Gi
        #     selector: {}
        externalUrl: ENC[AES256_GCM,data:XJMereuWIjGkuvlR33gdAw50568HxQByPKBYbWFA6RddPyFyP+DZ6Q==,iv:uk2A6GvAnZ83WeaN26FgicKK34KL34rGmWGPM5qN/Tk=,tag:YhFOH06Y7gxLMLhYlBUTIA==,type:str]
        resources:
            requests:
                cpu: 20m
                memory: 64Mi
            limits:
                cpu: 20m
                memory: 128Mi
grafana:
    enabled: false
kubernetesServiceMonitors:
    enabled: true
## Component scraping the kube api server
##
kubeApiServer:
    enabled: true
## Component scraping the kubelet and kubelet-hosted cAdvisor
##
kubelet:
    enabled: true
## Component scraping the kube controller manager
##
kubeControllerManager:
    enabled: false
## Component scraping coreDns. Use either this or kubeDns
##
coreDns:
    enabled: true
## Component scraping etcd
##
kubeEtcd:
    enabled: false
    endpoints: []
## Component scraping kube scheduler
##
kubeScheduler:
    enabled: false
## Component scraping kube proxy
##
kubeProxy:
    enabled: false
## Component scraping kube state metrics
##
kubeStateMetrics:
    enabled: true
## Deploy node exporter as a daemonset to all nodes
##
nodeExporter:
    enabled: true
prometheus-node-exporter:
    prometheus:
        monitor:
            enabled: true
            jobLabel: jobLabel
## Manages Prometheus and Alertmanager components
##
prometheusOperator:
    enabled: true
    kubeletEndpointsEnabled: false
    kubeletEndpointSliceEnabled: true
## Deploy a Prometheus instance
##
prometheus:
    enabled: true
    ingress:
        enabled: true
        ingressClassName: nginx
        annotations:
            nginx.ingress.kubernetes.io/auth-method: GET
            nginx.ingress.kubernetes.io/auth-url: http://authelia.ingress.svc.cluster.local/api/verify
            nginx.ingress.kubernetes.io/auth-signin: ENC[AES256_GCM,data:Zl/QEeahU7iz45Dwx9hUDP6Uh9MYiMG7/geUDtMRrKMPAyogqgB7ERU95+jy,iv:CJlifKDAgSeDb2kDrRAShWwfa22aXKwAAZIgRxeBiqI=,tag:yBUIxB3crH4elOTR9fOmuQ==,type:str]
            nginx.ingress.kubernetes.io/auth-response-headers: Remote-User,Remote-Name,Remote-Groups,Remote-Email
            nginx.ingress.kubernetes.io/auth-snippet: proxy_set_header X-Forwarded-Method $request_method;
        hosts:
            - ENC[AES256_GCM,data:wMcWINFawjnfaq19yyeFIA+hWWVppj9KIM2PHLRz,iv:eyjwANIFjgGbxq95IITJhAN32Z9dYDeSt+4M8M2aSkM=,tag:meFlQTkZJuUIeakvk2CpJQ==,type:str]
        tls:
            - secretName: local-wildcard-cert
    prometheusSpec:
        retention: 10d
        retentionSize: 20GiB
        walCompression: true
        logLevel: info
        resources:
            requests:
                cpu: 100m
                memory: 256Mi
                # limits:
                #   cpu: 2
                #   memory: 4Gi
        storageSpec:
            volumeClaimTemplate:
                spec:
                    storageClassName: longhorn-persistent
                    accessModes:
                        - ReadWriteOnce
                    resources:
                        requests:
                            storage: 25Gi
        ## List of scrape classes to expose to scraping objects such as
        ## PodMonitors, ServiceMonitors, Probes and ScrapeConfigs.
        ##
        scrapeClasses:
            - name: cluster-relabeling
              default: true
              relabelings:
                - action: replace
                  targetLabel: cluster
                  replacement: k3s-cluster
                - action: replace
                  sourceLabels:
                    - __meta_kubernetes_pod_node_name
                  targetLabel: hostname
                # 2. Fallback to endpoint node name if hostname is still empty
                - action: replace
                  sourceLabels:
                    - hostname
                    - __meta_kubernetes_endpoint_node_name
                  separator: ;
                  regex: ^;(.+)$
                  replacement: $1
                  targetLabel: hostname
sops:
    lastmodified: "2026-02-08T18:17:33Z"
    mac: ENC[AES256_GCM,data:QiZPGQoOCD8L/nLOFh0a0v6bKZ1HdLBKTlN2bMJ2do5GtWTU6BAw2WkaSuPT/K6GhU28eOcKdCJ6r+WJJqh1JMtV4s8HTCCLRpSaAtqR2fC2WEEljBXSwNGac8XrCz9pDCDOp13e5JldXXRTxbrQPdK9aFV3pZuQXYen1q4bcP0=,iv:i/uR8uMcZPN2Ur0ZejzTIAKDqAl1XdQaYISIXDLImxY=,tag:4bNrcDQGdUft4z4FJ9MN1g==,type:str]
    pgp:
        - created_at: "2026-02-08T18:14:38Z"
          enc: |-
            -----BEGIN PGP MESSAGE-----

            hQIMA5NT/LvuRqeGARAAn0Z6F+kaNdCSKG02Bwtgd7csH6SlwqW40CkrAiEgPNI/
            sd5z2iU6EwK2Qa21qvgJNNPa33VciMMS/xWumjHT3INiPc4LLb/pLctM0vaTW+oB
            x12ZYkrKIlYskAgxZDk9Ng77jA0pr4geKCosN86Khl8pj7cWS9ouMm6cCTizwsVN
            x1DflRppI9ZVscRO2hAv2jH3tnf5FKpiPU5sdmZ6tTv5xYTF1j7kc52w5JZQcj9M
            FrHnisbUOt4eatIyba7/vqYbVt66fOQEJgxnG8AAoWugwh91A8fLkOs7RYv3am8v
            jM7Ko+bDqkIAEFwK0vBbysSZcPBB+Da96YuvjiiLVf7u6dNsm8xY++a4xQdUr2VS
            5cjpDoDCixcxlHk+4FQs9Z57A2joNTXOG0gFw+u5jaur4hb5X9VxurDvIHS/fO2x
            2Yb6eXaMfBqJ2h6BIKlley3QZrNacgLCPnakY8c9RvRuHRuG+a016TxbhJr3OFsc
            IY74jIqYgzCXKhSVbn5WYZqceGRALpv0pyUNo+fRMEYmpN91vxrIBwQh96NAgF4n
            7cZetU1JMkILExcI7YQGMR+HU/lXZNtdUoLWderTxSTVqeWTBKefPNki4B8IgkhS
            0Ux7zAHAp01bpzlbaRNUvQi4Ng+DblaxbNDqrjSYETTrqjnMO7bVFvkRlnf9d4rU
            aAEJAhCHdxTaU5y8GpCpmpR/NCZndN6knJUNTCyZdD2PQW4XrA7FxxF6/bzlkvYg
            Dy4DFrXIeVPu32u/o5U9SzA8Vv3iqV/5yTNK/MB2S7jGtUa+ExS9r/qcfN2+UUJH
            il6Grkqjdin4
            =M7sR
            -----END PGP MESSAGE-----
          fp: 47E4999BED565F9874AA0E7C05DA03D000FC10D1
    encrypted_regex: ^(nginx.ingress.kubernetes.io/auth-signin|webhook_url|hosts|externalUrl|dashboard)$
    version: 3.11.0
